{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a PPi train + validation set from [APID](http://cicblade.dep.usal.es:8080/APID/init.action) and a Y2H test set from [HuRI](http://www.interactome-atlas.org/download)\n",
    "## prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- March 2021 version of [APID](http://cicblade.dep.usal.es:8080/APID/init.action)\n",
    "- interactomes for the 35 organisms listed as \"with more than 500 interactions\" only\n",
    "- some organism datasets will be dropped later, so not fetching smaller sets is ok\n",
    "- binary interactomes -> Level 2 -> `Q1` suffix\n",
    "- not using *H. sapiens* for training -> `9606_*Q1.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "first number is number of IDs, second is number of PPIs\n",
    "\n",
    "| APID     |              ISI |            noISI |      loss |\n",
    "|---------:|:----------------:|:----------------:|:---------:|\n",
    "| w/ Human | 67'240 : 319'429 | 61'429 : 296'653 | .09 : .07 |\n",
    "| no Human | 55'014 : 179'349 | 45'026 : 161'598 | .18 : .10 |\n",
    "|     loss |    .18 : .44     |    .27 : .46     | .33 : .49 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import importlib\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from dataclass_wizard import JSONWizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!which python\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# assert False, 'don\\'t run'\n",
    "# !mv apid.zip ../apid.zip\n",
    "# !mv hi_union.psi ../hi_union.psi\n",
    "# !ln ../apid.zip apid.zip\n",
    "# !ln ../hi_union.psi hi_union.psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "package_root = str(cwd.parent.parent)\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = '6072'\n",
    "\n",
    "shutil.copytree(cwd, cwd.with_name(session),\n",
    "                symlinks=True, dirs_exist_ok=True)\n",
    "os.chdir(cwd.with_name(session).resolve())\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data.utils import api, extract, general, pairs, plot, reduce\n",
    "\n",
    "from data.utils.api import *\n",
    "from data.utils.extract import *\n",
    "from data.utils.general import *\n",
    "from data.utils.pairs import *\n",
    "from data.utils.plot import *\n",
    "from data.utils.reduce import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Config(JSONWizard):\n",
    "    class _(JSONWizard.Meta):\n",
    "        key_transform_with_dump = 'SNAKE'\n",
    "\n",
    "    keep_human: bool = False\n",
    "    keep_interspecies: bool = False\n",
    "    keep_homodimers: bool = True\n",
    "    rostclust_pretend: bool = False\n",
    "\n",
    "    ap: Path = Path('apid_sequences')\n",
    "    hp: Path = Path('huri_sequences')\n",
    "    qp: Path = None\n",
    "\n",
    "    min_seq_len: int = 50\n",
    "    max_seq_len: int = 1500\n",
    "\n",
    "    psi_path = Path('hi_union.psi')\n",
    "    hval_config: dict = field(default_factory=dict)\n",
    "\n",
    "    seed: int = 64\n",
    "    ratio: float = 10.0\n",
    "    strategy: SamplingStrategy = SamplingStrategy.BALANCED\n",
    "\n",
    "    val_set_size: float = .1\n",
    "    val_species: Set[str] = field(default_factory=set)\n",
    "\n",
    "    val_raw_fasta: Path = ap / 'apid_validation_raw.fasta'\n",
    "    val_raw_tsv: Path = ap / 'apid_validation_raw.tsv'\n",
    "    val_rr_fasta: Path = ap / 'apid_validation_rr.fasta'\n",
    "    val_rr_tsv: Path = ap / 'apid_validation_rr.tsv'\n",
    "    val_c3_fasta: Path = ap / 'apid_validation_c3.fasta'\n",
    "    val_fasta: Path = Path('apid_validation.fasta')\n",
    "    val_tsv: Path = Path('apid_validation.tsv')\n",
    "\n",
    "    test_raw_fasta: Path = hp / 'huri_test_raw.fasta'\n",
    "    test_raw_tsv: Path = hp / 'huri_test_raw.tsv'\n",
    "    test_rr_fasta: Path = hp / 'huri_test_rr.fasta'\n",
    "    test_rr_tsv: Path = hp / 'huri_test_rr.tsv'\n",
    "    test_c3_fasta: Path = hp / 'huri_test_c3.fasta'\n",
    "    test_fasta: Path = Path('huri_test.fasta')\n",
    "    test_tsv: Path = Path('huri_test.tsv')\n",
    "\n",
    "    train_tsv: Path = Path('apid_train.tsv')\n",
    "    train_fasta: Path = Path('apid_train.fasta')\n",
    "    train_positives: Path = ap / 'apid_train_positives.tsv'\n",
    "\n",
    "    # results\n",
    "    weird_species: set[int] = field(default_factory=set)\n",
    "    train_bias: str = None\n",
    "    train_seqs: int = None\n",
    "    train_size: int = None\n",
    "    test_seqs: int = None\n",
    "    val_seqs: int = None\n",
    "    val_bias: str = None\n",
    "    val_size: int = None\n",
    "    val_sizes: str = None\n",
    "    test_bias: float = None\n",
    "    test_size: int = None\n",
    "    test_sizes: str = None\n",
    "\n",
    "\n",
    "val_species = {39947}\n",
    "hval_config = dict(shortAlignmentLen=50,\n",
    "                   longSeqLen=180,\n",
    "                   reduceRandomAlign=False,\n",
    "                   clusterThreshold=20)\n",
    "\n",
    "c = Config(hval_config=hval_config, val_species=val_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(api)\n",
    "importlib.reload(extract)\n",
    "importlib.reload(general)\n",
    "importlib.reload(pairs)\n",
    "importlib.reload(plot)\n",
    "importlib.reload(reduce)\n",
    "\n",
    "from data.utils.api import *\n",
    "from data.utils.extract import *\n",
    "from data.utils.general import *\n",
    "from data.utils.pairs import *\n",
    "from data.utils.plot import *\n",
    "from data.utils.reduce import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example\n",
    "#### bias of negative dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# demonstrate sampling strategies: toy PPI table example\n",
    "raw = '''A\\tB\\nA\\tC\\nC\\tF\\nA\\tE\\nK\\tL\\nC\\tK\\nB\\tG\\nG\\tM\\nA\\tO\\nE\\tO\\nI\\tJ\\nJ\\tK\\nI\\tK'''\n",
    "ppis = ppis_from_string(raw)\n",
    "ppi_dict = dict()\n",
    "ppis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppi_dict['balanced'], _ = find_negative_pairs(ppis, ratio=1.5, seed=42,\n",
    "                                              strategy=SamplingStrategy.BALANCED)\n",
    "# balanced sampling tries to conserve the distribution of degrees -> high-bias dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppi_dict['random'], _ = find_negative_pairs(ppis, ratio=1.5, seed=42,\n",
    "                                            strategy=SamplingStrategy.RANDOM)\n",
    "# random sampling gives a nearly un-biased dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppi_dict['complement'], _ = find_negative_pairs(ppis, ratio=10, seed=42,\n",
    "                                                strategy=SamplingStrategy.BALANCED)\n",
    "# sampling the entire network complement will perfectly invert the degree distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### strategies visualized\n",
    "It becomes apparent that the combination of graph size and density is important, and that random or balanced sampling generate different sets of negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = draw_toy_ppis(ppis, ppi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with homodimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# added F-F\n",
    "raw = '''A\\tB\\nA\\tC\\nC\\tF\\nA\\tE\\nK\\tL\\nC\\tK\\nB\\tG\\nG\\tM\\nA\\tO\\nE\\tO\\nI\\tJ\\nJ\\tK\\nI\\tK\\nF\\tF'''\n",
    "ppis = ppis_from_string(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppi_dict = dict()\n",
    "ppi_dict['balanced'], _ = find_negative_pairs(ppis, ratio=1.5, seed=42,\n",
    "                                              strategy=SamplingStrategy.BALANCED)\n",
    "ppi_dict['random'], _ = find_negative_pairs(ppis, ratio=1.5, seed=42,\n",
    "                                            strategy=SamplingStrategy.RANDOM)\n",
    "ppi_dict['complement'], _ = find_negative_pairs(ppis, ratio=10, seed=42,\n",
    "                                                strategy=SamplingStrategy.BALANCED)\n",
    "_ = draw_toy_ppis(ppis, ppi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input homodimers, but not allowed as negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppi_dict = dict()\n",
    "ppi_dict['balanced'], _ = find_negative_pairs(ppis, ratio=1.5, seed=42,\n",
    "                                              strategy=SamplingStrategy.BALANCED,\n",
    "                                              homodimers=False)\n",
    "ppi_dict['random'], _ = find_negative_pairs(ppis, ratio=1.5, seed=42,\n",
    "                                            strategy=SamplingStrategy.RANDOM,\n",
    "                                            homodimers=False)\n",
    "ppi_dict['complement'], _ = find_negative_pairs(ppis, ratio=10, seed=42,\n",
    "                                                strategy=SamplingStrategy.BALANCED,\n",
    "                                                homodimers=False)\n",
    "_ = draw_toy_ppis(ppis, ppi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train set: APID\n",
    "#### extract from `<taxid>*_Q1.txt` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.qp = unzip_apid(zip_path='apid.zip', keep_human=c.keep_human,\n",
    "                  keep_interspecies=c.keep_interspecies)\n",
    "c.qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uniprot_ids = extract_apid_uniprot_ids(c.qp)\n",
    "len(uniprot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppis = extract_apid_ppis(c.qp)\n",
    "len(ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interspecies interactions\n",
    "Check if there are PPIs (based on UniProt IDs) that occur in several species. We use APID `noISI` data per default, so the exclusion of this data is not implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "find_multi_species_ppis = lambda ppi_df: pd.concat(\n",
    "    [df for i, df in ppi_df.groupby(\n",
    "        ['UniprotID_A', 'UniprotID_B']) if len(df) > 1]\n",
    "    + [ppi_df.loc[ppi_df.species == 'is there a marsupilami?']])\n",
    "\n",
    "find_multi_species_ppis(ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# proof that actually worked: add some dummy data\n",
    "for i in [0, 1]:\n",
    "    s = ppis.iloc[i].copy()\n",
    "    s.species = 'marsupilami'\n",
    "    ppis = pd.concat([ppis, pd.DataFrame(s).T], axis=0)\n",
    "\n",
    "marsu = find_multi_species_ppis(ppis)\n",
    "\n",
    "# drop the dummy data\n",
    "ppis = ppis.loc[ppis.species != 'marsupilami']\n",
    "marsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or more generally protein IDs that occur in several species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "find_multi_species_proteins(ppis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### species lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pick a charismatic animal for validation!\n",
    "taxonomy = fetch_taxonomic_info(ppis.species)\n",
    "taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # if you are re-running this without changes above or deleting files, skip!\n",
    "# _ = uniprot_api_fetch(uniprot_ids, c.ap / 'apid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map IDs to seq hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hash_ppis = ppis_to_hashes(ppis, c.ap / 'apid.json').drop_duplicates()\n",
    "hash_ppis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(ppis) - len(hash_ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fasta = SeqIO.to_dict(SeqIO.parse(c.ap / 'apid.hash.fasta', 'fasta'))\n",
    "len(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter by seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.min_seq_len, c.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_hash_ppis, _fasta, fig = filter_ppis_and_fasta_by_len(\n",
    "    hash_ppis, fasta, c.min_seq_len, c.max_seq_len)\n",
    "len(fasta), len(_fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue if these limits were ok, or change/set the values for\n",
    "`cfg.min_seq_len, cfg.max_seq_len` and re-run the filtering cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hash_ppis = _hash_ppis\n",
    "fasta = _fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### homodimer share\n",
    "Overall count, share, overall PPI count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_homodimer_share(hash_ppis)\n",
    "c.keep_homodimers, *count_homodimers(hash_ppis),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not c.keep_homodimers:\n",
    "    hash_ppis = drop_homodimers(hash_ppis)\n",
    "    hash_ppis, fasta = shrink_both_ways(hash_ppis, fasta)\n",
    "    len(hash_ppis), len(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set: negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.ratio, c.seed, c.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ppis, train_negs, train_bias = make_train_negatives(\n",
    "    hash_ppis, ratio=c.ratio, seed=c.seed, strategy=c.strategy, homodimers=c.keep_homodimers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### species without negatives or a constant Pearson/Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_bias.loc[train_bias.bias.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weird_species = set(train_bias.loc[train_bias.bias.isna(), 'species'])\n",
    "train_ppis.loc[train_ppis['species'].isin(weird_species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_negs.loc[train_negs['species'].isin(weird_species)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very little data that we can safely drop. For curiosity's sake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "taxonomy.loc[taxonomy.species.isin(weird_species)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's actually ok to just drop these organisms at this point - no need to backpropagate this farther up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# actually drop the data here\n",
    "train_ppis, train_negs, train_bias = [df.loc[~df.species.isin(weird_species)]\n",
    "                                      for df in (train_ppis, train_negs, train_bias)]\n",
    "c.weird_species = weird_species\n",
    "len(train_ppis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set size and bias\n",
    "This is *before* the extraction of the validation set and therefor preliminary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_bias(train_ppis, train_negs, train_bias, c.ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set: APID\n",
    "#### val: select species/proteins\n",
    "Either by sampling a subset of proteins and selecting the PPIs or picking the ones for one or more particular species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.val_set_size, c.val_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # just a suggestion\n",
    "# val_species = {7955, 9031, 9913, 10377, 37296, 39947}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_ppis['label'] = 1\n",
    "if c.val_species is not None:\n",
    "    train, val = make_validation_species(train_ppis, c.val_species)\n",
    "    train_negs = train_negs.loc[~train_negs.species.isin(c.val_species)]\n",
    "else:\n",
    "    # if the set becomes too large, try another seed! With this approach, PPIs *will* be lost\n",
    "    train, val = make_validation_split(train_ppis, c.val_set_size, c.seed)\n",
    "len(train), len(train) / len(train_ppis), len(val), len(val) / len(train_ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val.species.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train: select / re-sample negatives\n",
    "We have already generated negatives above. If we want to use them, we have to drop the negatives with a protein not in the `train` PPIs, then take the rest as training set negatives. But let's also look at the bias of this cropped set! (Resample negatives for `val` later, after redundancy reduction.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_proteins = set(np.unique(train.iloc[:, [0, 1]]))\n",
    "_train_negs = train_negs.loc[(train_negs.hash_A.isin(train_proteins))\n",
    "                             & (train_negs.hash_B.isin(train_proteins))]\n",
    "len(_train_negs), len(train_negs), len(_train_negs) / len(train_negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "estimate_bias(train, _train_negs, corrtype=CorrelationType.SPEARMAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "estimate_bias(train, _train_negs, corrtype=CorrelationType.PEARSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_bias(train, _train_negs, train_bias, c.ratio)\n",
    "fig.savefig('train_bias_0_og.png', transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redraw a set of negative anyway to see if it would fit significantly better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_ppis, t_negs, t_bias = make_train_negatives(train, c.strategy, c.ratio, c.seed, c.keep_homodimers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# drop na data\n",
    "t_ppis = t_ppis.loc[~t_ppis.species.isin(t_bias.loc[t_bias.bias.isna()].species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_bias(t_ppis, t_negs, t_bias, c.ratio)\n",
    "fig.savefig('train_bias_1_resample.png', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pick one!\n",
    "picked_idx = 1\n",
    "train_all = [pd.concat((train, _train_negs)), pd.concat((t_ppis, t_negs))][picked_idx]\n",
    "c.train_bias = [train_bias.to_json(), t_bias.to_json()][picked_idx]\n",
    "len(train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the validation set sequences from the ones remaining as train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, train_seqs = shrink_both_ways(train_all.copy(), fasta.copy())\n",
    "c.train_seqs = len(train_seqs)\n",
    "len(train_seqs), len(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train: save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = SeqIO.write(values_sorted_by_key(train_seqs), c.train_fasta, 'fasta')\n",
    "train_all.to_csv(c.train_tsv, sep='\\t', header=True, index=False)\n",
    "c.train_size = len(train_all)\n",
    "c.train_fasta, c.train_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### val: save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, val_seqs = shrink_both_ways(val.copy(), fasta.copy())\n",
    "len(val_seqs), len(fasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind that the TSV will contain only positives! Sample negatives only after the whole `uniqueprot`-shebang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = SeqIO.write(values_sorted_by_key(val_seqs), c.val_raw_fasta, 'fasta')\n",
    "val.to_csv(c.val_raw_tsv, sep='\\t', header=True, index=False)\n",
    "c.val_raw_fasta, c.val_raw_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test set: HuRI\n",
    "#### download and extract PPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.psi_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# it's somehow a lot faster to download this from a browser!\n",
    "# or run !wget \"http://www.interactome-atlas.org/data/HI-union.psi\" -O \"hi_union.psi\"\n",
    "download_y2h_interactome(c.psi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "huri_ppis, huri_seq_ids = extract_huri_ppis(c.psi_path)\n",
    "len(huri_ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "huri_seqs, _ = fetch_huri_seqs(huri_seq_ids, c.hp / 'huri')\n",
    "len(huri_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map + filter PPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(set(huri_ppis.species))  # only human, but keep the label\n",
    "huri_ppis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "huri_hash_ppis = ppis_to_hashes(huri_ppis, c.hp / 'huri.json')\n",
    "len(huri_ppis) - len(huri_hash_ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "huri_hash_ppis = remove_ids_from(huri_hash_ppis, black_list_fasta=c.train_fasta)\n",
    "len(huri_hash_ppis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "*count_homodimers(huri_hash_ppis), c.keep_homodimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not c.keep_homodimers:\n",
    "    huri_hash_ppis = drop_homodimers(huri_hash_ppis)\n",
    "    huri_hash_ppis, huri_seqs = shrink_both_ways(huri_hash_ppis, huri_seqs)\n",
    "    len(huri_hash_ppis), len(huri_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_huri_hash_ppis, _huri_seqs, fig = filter_ppis_and_fasta_by_len(\n",
    "    huri_hash_ppis, huri_seqs, c.min_seq_len, c.max_seq_len)\n",
    "len(huri_seqs), len(_huri_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "huri_hash_ppis = _huri_hash_ppis\n",
    "huri_seqs = _huri_seqs\n",
    "_ = SeqIO.write(huri_seqs.values(), c.test_raw_fasta, 'fasta')\n",
    "huri_hash_ppis.to_csv(c.test_raw_tsv, sep='\\t', header=True, index=False)\n",
    "c.test_raw_fasta, c.test_raw_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundancy Reduction with [rostclust](https://git.rostlab.org/bernhoferm/mmseqs2-uniqueprot/-/tree/F_typer_app)\n",
    "\n",
    "**Don't run the next cells in the wrong order, and don't forget to copy the files back and forth if you are running `rostclust` elsewhere! <br>In particular, copy files after `shrink_files_both_ways`. Was that name not clear?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.hval_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### redundancy-reduce test and validation\n",
    "The flag below allows me to test this notebook without the MMseqs2 runs. Leave `rostclust_pretend` at `True` and copy the two result files to this folder; or run `rostclust uniqueprot[2D]` now and here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.rostclust_pretend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if c.rostclust_pretend:\n",
    "    !rsync -zar -e ssh \".\" \"kaindll@lapislazuli:/home/k/kaindll/ppi/data/ppi_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# redundancy-reduce the test set\n",
    "run_uniqueprot(c.test_raw_fasta, c.test_rr_fasta, c.hval_config, pretend=c.rostclust_pretend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# and validation\n",
    "run_uniqueprot(c.val_raw_fasta, c.val_rr_fasta, c.hval_config, pretend=c.rostclust_pretend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if c.rostclust_pretend:\n",
    "    !rsync -zar -e ssh \"kaindll@lapislazuli:/home/k/kaindll/ppi/data/ppi_dataset/\" \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fastalen = lambda _file: len([r.id for r in SeqIO.parse(_file, 'fasta')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# also drop PPIs accordingly\n",
    "assert c.test_rr_fasta.is_file()\n",
    "shrink_files_both_ways(c.test_raw_tsv, c.test_rr_fasta,\n",
    "                       new_tsv_name=c.test_rr_tsv,\n",
    "                       new_fasta_name=c.test_fasta)  # finished!\n",
    "c.test_seqs = fastalen(c.test_fasta)\n",
    "assert c.val_rr_fasta.is_file()\n",
    "shrink_files_both_ways(c.val_raw_tsv, c.val_rr_fasta,\n",
    "                       new_tsv_name=c.val_rr_tsv,\n",
    "                       new_fasta_name=c.val_fasta)  # finished!\n",
    "c.val_seqs = fastalen(c.val_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if c.rostclust_pretend:\n",
    "    !rsync -zar -e ssh \".\" \"kaindll@lapislazuli:/home/k/kaindll/ppi/data/ppi_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cluster `test` and `val` against `train`\n",
    "\n",
    "First, cluster the `HuRI` test set against the `APID` train set to get **C1-3** labels for the final test PPIs. Then, cluster the `APID` validation set against the `APID` train set, which gives us **C1-3** labels for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_uniqueprot2D(c.test_fasta, c.train_fasta, c.test_c3_fasta,\n",
    "                 hval_config=c.hval_config, pretend=c.rostclust_pretend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_uniqueprot2D(c.val_fasta, c.train_fasta, c.val_c3_fasta,\n",
    "                 hval_config=c.hval_config, pretend=c.rostclust_pretend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if c.rostclust_pretend:\n",
    "    !rsync -zar -e ssh \"kaindll@lapislazuli:/home/k/kaindll/ppi/data/ppi_dataset/\" \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert c.test_c3_fasta.is_file()\n",
    "assert c.val_c3_fasta.is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negatives\n",
    "\n",
    "Negatives are sampled *per species*. Mind that the test set is human-only!\n",
    "Also, identify and assign **C1/C2/C3** class labels at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "c.ratio, c.seed, c.strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APID val: generate & classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check if there are any proteins in test that\n",
    "# were already in train. re: \"do not add back in identical ones\"\n",
    "assert not ({r.id for r in SeqIO.parse(c.train_fasta, 'fasta')} & {\n",
    "    r.id for r in SeqIO.parse(c.test_fasta, 'fasta')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for p in [c.val_rr_tsv, c.val_c3_fasta, c.val_fasta]:\n",
    "    assert p.is_file(), f'missing {p}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_ppis, val_negatives, val_bias = make_test_negatives(\n",
    "    c.val_rr_tsv, c.val_c3_fasta, c.val_fasta, c.strategy,\n",
    "    c.ratio, c.seed, c.keep_homodimers)\n",
    "c.val_bias = str(val_bias) if type(val_bias) == np.float64 else val_bias.to_json()\n",
    "val_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_ppis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if type(val_bias) != np.float64:\n",
    "    fig = plot_bias(val_ppis, val_negatives, val_bias, c.ratio)\n",
    "    fig.savefig('val_bias.png', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_all = pd.concat([val_ppis, val_negatives])\n",
    "c.val_size = len(val_all)\n",
    "len(val_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context({'figure.dpi': 100}):\n",
    "    fig = plot_c_classes(val_all)\n",
    "    c.val_sizes = val_all[['cclass', 'label']].value_counts().to_json()\n",
    "    fig.savefig('val_cclasses.png', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# have a direct look at the (ranked) degrees, but only for some species\n",
    "n_degrees_per_sp = fetch_degrees(val_all).groupby('species')[\n",
    "    'x'].size().sort_values(ascending=False)\n",
    "# pick two larger and two smaller species sets\n",
    "sps = list(n_degrees_per_sp.index)[:2] + list(n_degrees_per_sp.index)[-5:-3]\n",
    "print(sps)\n",
    "n_degrees_per_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context({'figure.dpi': 72 if len(sps) > 2 else 200}):\n",
    "    # can't unFUBAR the axis limits ...\n",
    "    fig = plot_test_degrees(val_all.loc[val_all.species.isin(sps)], c.ratio, flip=False)\n",
    "    fig.savefig('val_degrees.png', transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APID val: save TSV\n",
    "The `FASTA` was finalized already, right after the redundancy reduction and before clustering against `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_all.to_csv(c.val_tsv, sep='\\t', header=True, index=False)\n",
    "c.val_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuRI test: generate & classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for p in [c.test_rr_tsv, c.test_c3_fasta, c.test_fasta]:\n",
    "    assert p.is_file(), f'missing {p}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_ppis, test_negatives, test_bias = make_test_negatives(\n",
    "    c.test_rr_tsv, c.test_c3_fasta, c.test_fasta, c.strategy,\n",
    "    c.ratio, c.seed, c.keep_homodimers)\n",
    "c.test_bias = test_bias\n",
    "test_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_ppis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_all = pd.concat([test_ppis, test_negatives])\n",
    "c.test_size = len(test_all)\n",
    "len(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context({'figure.dpi': 100}):\n",
    "    fig = plot_c_classes(test_all)\n",
    "    c.test_sizes = test_all[['cclass', 'label']].value_counts().to_json()\n",
    "    fig.savefig('test_cclasses.png', transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_test_degrees(test_all, c.ratio)\n",
    "fig.savefig('test_degrees.png', transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuRI test: save TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_all.to_csv(c.test_tsv, sep='\\t', header=True, index=False)\n",
    "c.test_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with Path(f'cfg.json').open('w') as json_file:\n",
    "    json_file.write(c.to_json(indent=2))\n",
    "print(c.to_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}